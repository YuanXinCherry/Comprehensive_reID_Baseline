# [VIPeR](https://vision.soe.ucsc.edu/node/178)

This dataset contains two cameras, each of which captures one image per person. It also provides the viewpoint angle of each image. Although it has been tested by many researchers, it's still one of the most challenging datasets. Ryan Layne provides the attribute annotation of VIPeR here.



>D. Gray and Tao, H., [“Viewpoint Invariant Pedestrian Recognition with an Ensemble of Localized Features”](https://link.springer.com/content/pdf/10.1007/978-3-540-88682-2_21.pdf), in ECCV '08: Proceedings of the 10th European Conference on Computer Vision, Berlin, Heidelberg, 2008, pp. 262–275.
>
>D. Gray, Brennan, S., and Tao, H., “Evaluating Appearance Models for Recognition, Reacquisition, and Tracking”, in 10th IEEE International Workshop on Performance Evaluation of Tracking and Surveillance (PETS), 2007.
